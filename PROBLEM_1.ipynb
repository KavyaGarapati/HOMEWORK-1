{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "PROBLEM 1.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/KavyaGarapati/HOMEWORK-1/blob/master/PROBLEM_1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "j1jRCsL7ow8X",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import keras\n",
        "from keras.datasets import mnist\n",
        "import numpy as np\n",
        "import math\n",
        "from keras.utils import np_utils\n",
        "import tensorflow as tf"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "x3yitIWgo4Fu",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def to_categorical(y,nb_classes):\n",
        "  output = []\n",
        "  for i in y:\n",
        "    temp = np.zeros(nb_classes)\n",
        "    temp[i] = 1\n",
        "    output.append(temp)\n",
        "  output = np.array(output)\n",
        "  output = output.reshape(y.shape[0],nb_classes)\n",
        "  return output"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "PE8DgUG-o8wl",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def init(dim):\n",
        "    W = np.zeros(shape=(dim, num_classes))\n",
        "    b = 0\n",
        "    return W, b"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "D1iUbSXco_66",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def sigmoid(z):\n",
        "    return 1/(1+np.exp(-z))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "7VCIbSdApKTz",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def mse(A, B):\n",
        "    loss = np.mean((B - A)**2)\n",
        "    loss = np.squeeze(loss)\n",
        "    return loss"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "wc7BTzoH3h3s",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def forw_prop(W, b, X):\n",
        "    linear_transformation = np.dot(W.T, X) + b\n",
        "    output = sigmoid(linear_transformation)\n",
        "    return output"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "1o2-v_5WpNjM",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def back_prop(A, X, B, batch_size):\n",
        "    m = batch_size\n",
        "    dW = (1 / m) * np.dot(X, ((A-B) * A * (1-A)).T)         \n",
        "    db = (1 / m) * np.sum((A-B) * A * (1-A))\n",
        "    return dW, db\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "uA3wO6MDpYY-",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def sgd(W, b, X, Y, epochs, learning_rate):\n",
        "\n",
        "    for j in range(epochs):\n",
        "        training_loss = []\n",
        "        for i in range(0, X.shape[1], batch_size):\n",
        "            x_train_mini = X.T[i:i+batch_size]\n",
        "            y_train_mini = Y.T[i:i+batch_size]\n",
        "            output = forw_prop(W,b,x_train_mini.T)\n",
        "            loss = mse(output,y_train_mini.T)\n",
        "            dW, db = back_prop(output,x_train_mini.T,y_train_mini.T,batch_size)\n",
        "            W = W - learning_rate * dW                    # gradient descent\n",
        "            b = b - learning_rate * db\n",
        "        training_loss.append(loss)\n",
        "        epochLoss=sum(training_loss)/len(training_loss)\n",
        "        print(\"Epoch {}/{}\\t-loss : {}\".format(j+1,epochs,round(epochLoss,2)))\n",
        "    return W, b"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "fub00srhpcZS",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def predict(W, b, X):\n",
        "\n",
        "    m = X.shape[1]\n",
        "    y_pred = np.zeros((1, m))\n",
        "    W = W.reshape(X.shape[0], num_classes)\n",
        "    A = forward_propogate(W,b,X)\n",
        "\n",
        "    for i in range(A.shape[1]):\n",
        "        y_pred[0, i] = 1 if A[0, i] > 0.5 else 0\n",
        "\n",
        "    return y_pred"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "HiD4Mjq1qph3",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def model(X_train, Y_train, X_test, Y_test, epochs=50, learning_rate=0.1):\n",
        "\n",
        "    y_train_pred = Y_train\n",
        "    y_test_pred = Y_test\n",
        "\n",
        "    \n",
        "    y_train_pred = to_categorical(y_train_pred, 10)\n",
        "    y_test_pred = to_categorical(y_test_pred, 10)\n",
        "\n",
        "    test_accuracy_list=[]\n",
        "    for i in range(0, 10):\n",
        "        # classifier digit\n",
        "        classifier = i\n",
        "        print(\"\\nClassifier: {}\".format(classifier))\n",
        "      \n",
        "        y_train_modified = np.array(Y_train)\n",
        "        y_train_modified = np.where(y_train_modified == classifier, 1, 0)\n",
        "\n",
        "        y_test_modified = np.array(Y_test)\n",
        "        y_test_modified = np.where(y_test_modified == classifier, 1, 0)\n",
        "\n",
        "        W, b = init(X_train.shape[0])\n",
        "        W, b = sgd(W, b, X_train, y_train_modified, epochs, learning_rate)\n",
        "\n",
        "        # predicting the values\n",
        "        Y_prediction_train = predict(W, b, X_train)\n",
        "        Y_prediction_test = predict(W, b, X_test)\n",
        "\n",
        "        # storing the values\n",
        "        y_train_pred[:, [i]] = Y_prediction_train.T\n",
        "        y_test_pred[:, [i]] = Y_prediction_test.T\n",
        "\n",
        "        train_accuracy = round((100 - np.mean(np.abs(Y_prediction_train - y_train_modified)) * 100),4)\n",
        "        test_accuracy = round((100 - np.mean(np.abs(Y_prediction_test - y_test_modified)) * 100),4)\n",
        "        test_accuracy_list.append(test_accuracy)\n",
        "\n",
        "        print(\"\\nAccuracy of classifer {} in training : {} %\".format(i, train_accuracy))\n",
        "        print(\"Accuracy of classifer {} in testing : {} %\".format(i, test_accuracy))\n",
        "        print(\"\\n\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "eYp36RAXqsal",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "    Y_train = to_categorical(Y_train, 10)\n",
        "    Y_test = to_categorical(Y_test, 10)\n",
        "    # test and train classifier accuracy of the network\n",
        "    print(\"Overall accuracy in Training: {} %\".format(round((100 - np.mean(np.abs(y_train_pred - Y_train)) * 100),4)))\n",
        "    print(\"Overall accuracy in Testing: {} %\".format(round((100 - np.mean(np.abs(y_test_pred - Y_test)) * 100),4)))\n",
        "    print(\"Classifier with Strongest output is: \",np.argmax(test_accuracy_list))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "XtM3Qlm7rBD_",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "batch_size = 32\n",
        "num_classes = 1\n",
        "epochs = 10\n",
        "rows = 28\n",
        "cols = 28"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "FpFFRsH5rExj",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# loading dataset\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Rj7jF9rIrH7C",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "x_train = x_train.reshape(x_train.shape[0], x_train.shape[1]*x_train.shape[2]).T\n",
        "x_test = x_test.reshape(x_test.shape[0], x_test.shape[1]*x_test.shape[2]).T\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ztYvIdH1rK9c",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "x_train = x_train / 255\n",
        "x_test = x_test / 255\n",
        "\n",
        "y_train = y_train.T\n",
        "y_test = y_test.T\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "EGs-Rh9krOSH",
        "colab_type": "code",
        "outputId": "5325ca17-fbd9-486a-c5f4-8888e3e90056",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 2907
        }
      },
      "cell_type": "code",
      "source": [
        "model(x_train, y_train, x_test, y_test, epochs=10,learning_rate=0.01)"
      ],
      "execution_count": 152,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Classifier: 0\n",
            "Epoch 1/10\t-loss : 0.05\n",
            "Epoch 2/10\t-loss : 0.04\n",
            "Epoch 3/10\t-loss : 0.04\n",
            "Epoch 4/10\t-loss : 0.03\n",
            "Epoch 5/10\t-loss : 0.03\n",
            "Epoch 6/10\t-loss : 0.03\n",
            "Epoch 7/10\t-loss : 0.03\n",
            "Epoch 8/10\t-loss : 0.03\n",
            "Epoch 9/10\t-loss : 0.03\n",
            "Epoch 10/10\t-loss : 0.03\n",
            "\n",
            "Accuracy of classifer 0 in training : 98.6667 %\n",
            "Accuracy of classifer 0 in testing : 98.94 %\n",
            "\n",
            "\n",
            "\n",
            "Classifier: 1\n",
            "Epoch 1/10\t-loss : 0.03\n",
            "Epoch 2/10\t-loss : 0.02\n",
            "Epoch 3/10\t-loss : 0.01\n",
            "Epoch 4/10\t-loss : 0.01\n",
            "Epoch 5/10\t-loss : 0.01\n",
            "Epoch 6/10\t-loss : 0.01\n",
            "Epoch 7/10\t-loss : 0.01\n",
            "Epoch 8/10\t-loss : 0.01\n",
            "Epoch 9/10\t-loss : 0.0\n",
            "Epoch 10/10\t-loss : 0.0\n",
            "\n",
            "Accuracy of classifer 1 in training : 98.775 %\n",
            "Accuracy of classifer 1 in testing : 99.01 %\n",
            "\n",
            "\n",
            "\n",
            "Classifier: 2\n",
            "Epoch 1/10\t-loss : 0.07\n",
            "Epoch 2/10\t-loss : 0.05\n",
            "Epoch 3/10\t-loss : 0.04\n",
            "Epoch 4/10\t-loss : 0.04\n",
            "Epoch 5/10\t-loss : 0.03\n",
            "Epoch 6/10\t-loss : 0.03\n",
            "Epoch 7/10\t-loss : 0.03\n",
            "Epoch 8/10\t-loss : 0.03\n",
            "Epoch 9/10\t-loss : 0.03\n",
            "Epoch 10/10\t-loss : 0.03\n",
            "\n",
            "Accuracy of classifer 2 in training : 97.195 %\n",
            "Accuracy of classifer 2 in testing : 97.36 %\n",
            "\n",
            "\n",
            "\n",
            "Classifier: 3\n",
            "Epoch 1/10\t-loss : 0.03\n",
            "Epoch 2/10\t-loss : 0.02\n",
            "Epoch 3/10\t-loss : 0.01\n",
            "Epoch 4/10\t-loss : 0.01\n",
            "Epoch 5/10\t-loss : 0.01\n",
            "Epoch 6/10\t-loss : 0.01\n",
            "Epoch 7/10\t-loss : 0.01\n",
            "Epoch 8/10\t-loss : 0.01\n",
            "Epoch 9/10\t-loss : 0.01\n",
            "Epoch 10/10\t-loss : 0.01\n",
            "\n",
            "Accuracy of classifer 3 in training : 96.6667 %\n",
            "Accuracy of classifer 3 in testing : 96.92 %\n",
            "\n",
            "\n",
            "\n",
            "Classifier: 4\n",
            "Epoch 1/10\t-loss : 0.04\n",
            "Epoch 2/10\t-loss : 0.03\n",
            "Epoch 3/10\t-loss : 0.02\n",
            "Epoch 4/10\t-loss : 0.02\n",
            "Epoch 5/10\t-loss : 0.02\n",
            "Epoch 6/10\t-loss : 0.02\n",
            "Epoch 7/10\t-loss : 0.02\n",
            "Epoch 8/10\t-loss : 0.02\n",
            "Epoch 9/10\t-loss : 0.02\n",
            "Epoch 10/10\t-loss : 0.02\n",
            "\n",
            "Accuracy of classifer 4 in training : 97.5967 %\n",
            "Accuracy of classifer 4 in testing : 97.42 %\n",
            "\n",
            "\n",
            "\n",
            "Classifier: 5\n",
            "Epoch 1/10\t-loss : 0.06\n",
            "Epoch 2/10\t-loss : 0.04\n",
            "Epoch 3/10\t-loss : 0.03\n",
            "Epoch 4/10\t-loss : 0.03\n",
            "Epoch 5/10\t-loss : 0.03\n",
            "Epoch 6/10\t-loss : 0.02\n",
            "Epoch 7/10\t-loss : 0.02\n",
            "Epoch 8/10\t-loss : 0.02\n",
            "Epoch 9/10\t-loss : 0.02\n",
            "Epoch 10/10\t-loss : 0.02\n",
            "\n",
            "Accuracy of classifer 5 in training : 96.035 %\n",
            "Accuracy of classifer 5 in testing : 96.25 %\n",
            "\n",
            "\n",
            "\n",
            "Classifier: 6\n",
            "Epoch 1/10\t-loss : 0.06\n",
            "Epoch 2/10\t-loss : 0.04\n",
            "Epoch 3/10\t-loss : 0.03\n",
            "Epoch 4/10\t-loss : 0.03\n",
            "Epoch 5/10\t-loss : 0.03\n",
            "Epoch 6/10\t-loss : 0.02\n",
            "Epoch 7/10\t-loss : 0.02\n",
            "Epoch 8/10\t-loss : 0.02\n",
            "Epoch 9/10\t-loss : 0.02\n",
            "Epoch 10/10\t-loss : 0.02\n",
            "\n",
            "Accuracy of classifer 6 in training : 98.2567 %\n",
            "Accuracy of classifer 6 in testing : 98.16 %\n",
            "\n",
            "\n",
            "\n",
            "Classifier: 7\n",
            "Epoch 1/10\t-loss : 0.04\n",
            "Epoch 2/10\t-loss : 0.03\n",
            "Epoch 3/10\t-loss : 0.03\n",
            "Epoch 4/10\t-loss : 0.03\n",
            "Epoch 5/10\t-loss : 0.02\n",
            "Epoch 6/10\t-loss : 0.02\n",
            "Epoch 7/10\t-loss : 0.02\n",
            "Epoch 8/10\t-loss : 0.02\n",
            "Epoch 9/10\t-loss : 0.02\n",
            "Epoch 10/10\t-loss : 0.02\n",
            "\n",
            "Accuracy of classifer 7 in training : 97.99 %\n",
            "Accuracy of classifer 7 in testing : 98.04 %\n",
            "\n",
            "\n",
            "\n",
            "Classifier: 8\n",
            "Epoch 1/10\t-loss : 0.07\n",
            "Epoch 2/10\t-loss : 0.05\n",
            "Epoch 3/10\t-loss : 0.04\n",
            "Epoch 4/10\t-loss : 0.04\n",
            "Epoch 5/10\t-loss : 0.03\n",
            "Epoch 6/10\t-loss : 0.03\n",
            "Epoch 7/10\t-loss : 0.03\n",
            "Epoch 8/10\t-loss : 0.03\n",
            "Epoch 9/10\t-loss : 0.02\n",
            "Epoch 10/10\t-loss : 0.02\n",
            "\n",
            "Accuracy of classifer 8 in training : 94.4883 %\n",
            "Accuracy of classifer 8 in testing : 94.2 %\n",
            "\n",
            "\n",
            "\n",
            "Classifier: 9\n",
            "Epoch 1/10\t-loss : 0.08\n",
            "Epoch 2/10\t-loss : 0.06\n",
            "Epoch 3/10\t-loss : 0.05\n",
            "Epoch 4/10\t-loss : 0.04\n",
            "Epoch 5/10\t-loss : 0.04\n",
            "Epoch 6/10\t-loss : 0.04\n",
            "Epoch 7/10\t-loss : 0.03\n",
            "Epoch 8/10\t-loss : 0.03\n",
            "Epoch 9/10\t-loss : 0.03\n",
            "Epoch 10/10\t-loss : 0.03\n",
            "\n",
            "Accuracy of classifer 9 in training : 95.3283 %\n",
            "Accuracy of classifer 9 in testing : 95.51 %\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}